# Recurrent Neural Networks and Language Models

- [Slide](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture06-rnnlm.pdf)
- [Note](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf)
- Suggested Readings:
    1. [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
    2. [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
    3. [Sequence Modeling: Recurrent and Recursive Neural Nets](http://www.deeplearningbook.org/contents/rnn.html) (Sections 10.1 and 10.2)
    4. [On Chomsky and the Two Cultures of Statistical Learning](http://norvig.com/chomsky.html)
